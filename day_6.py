# -*- coding: utf-8 -*-
"""day_6.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/144VUQ4H9WmGoZnBZ-CMa6sheNRbtxnGC
"""

# 1. Load and normalize dataset
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay

# Load CSV
df = pd.read_csv("/content/sample_data/Iris.csv")

# Features & target
X = df.iloc[:, 1:5]   # columns: sepal_length ... petal_width
y = df['Species']

# Encode species names into numbers
le = LabelEncoder()
y = le.fit_transform(y)

# Normalize features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42
)

# 2 & 3. Test multiple K values (loop-free style)
k_values = np.arange(1, 11)
accuracies = [
    accuracy_score(y_test, KNeighborsClassifier(n_neighbors=k).fit(X_train, y_train).predict(X_test))
    for k in k_values
]

# Select best K
best_k = k_values[np.argmax(accuracies)]
print("K values tested:", list(k_values))
print("Accuracies:", accuracies)
print("Best K:", best_k)

# 4. Train final model
knn = KNeighborsClassifier(n_neighbors=best_k)
knn.fit(X_train, y_train)
y_pred = knn.predict(X_test)

# Accuracy and confusion matrix
print("Final Accuracy:", accuracy_score(y_test, y_pred))
cm = confusion_matrix(y_test, y_pred)
ConfusionMatrixDisplay(cm, display_labels=le.classes_).plot(cmap="Blues")
plt.show()

# 5. Decision boundary visualization (first two features)
X_2d = X_scaled[:, :2]  # first two features only
X_train_2d, X_test_2d, y_train_2d, y_test_2d = train_test_split(
    X_2d, y, test_size=0.2, random_state=42
)
knn_2d = KNeighborsClassifier(n_neighbors=best_k)
knn_2d.fit(X_train_2d, y_train_2d)

# Meshgrid for boundary
x_min, x_max = X_2d[:, 0].min() - 1, X_2d[:, 0].max() + 1
y_min, y_max = X_2d[:, 1].min() - 1, X_2d[:, 1].max() + 1
xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),
                     np.arange(y_min, y_max, 0.02))

Z = knn_2d.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)

# Plot decision boundary
plt.figure(figsize=(8, 6))
plt.contourf(xx, yy, Z, alpha=0.3, cmap=plt.cm.Set1)
sns.scatterplot(x=X_2d[:, 0], y=X_2d[:, 1], hue=le.inverse_transform(y),
                palette="Set1", edgecolor="k", s=60)
plt.xlabel(X.columns[0])
plt.ylabel(X.columns[1])
plt.title(f"KNN Decision Boundary (K={best_k})")
plt.show()

